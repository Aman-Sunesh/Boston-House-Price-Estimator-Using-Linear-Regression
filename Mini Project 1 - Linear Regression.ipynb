{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd5e0f1-13e3-4e2d-825d-57acc4635227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "## Avoid printing out warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "     warnings.filterwarnings(\"ignore\")\n",
    "     X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c62a382-f1a6-4fa3-b3ed-d201eab95817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb53ec5-1ad9-4c29-84a8-bcbb310941b8",
   "metadata": {},
   "source": [
    "506 examples and 13 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba280e-6945-4e83-9e90-ab808a033b5e",
   "metadata": {},
   "source": [
    "# Implementing Normal Equation Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b128893-5ef4-4eca-b1cf-d39ac025e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training MSE: 21.39939241710581\n",
      "Average Test MSE: 34.705255944527316\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Splitting the dataset into train set and test set\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    m_train, m_test = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "    # Appending a column of ones to X_train and X_test to account for the bias term \n",
    "    X_train = np.append(X_train, np.ones((m_train,1)), axis = 1)\n",
    "    X_test = np.append(X_test, np.ones((m_test, 1)), axis=1)\n",
    "\n",
    "    # Reshaping y_train and y_test\n",
    "    y_train = y_train.reshape(m_train,1)\n",
    "    y_test = y_test.reshape(m_test,1)\n",
    "\n",
    "    # Computing Theta using the Normal Equation (Closed-Form Solution)\n",
    "    theta = np.dot(np.linalg.inv(np.dot(X_train.T, X_train)), np.dot(X_train.T, y_train))\n",
    "\n",
    "    # Evaluating the model on the train set\n",
    "    y_train_hat = X_train.dot(theta)\n",
    "    mse_train = (1/m_train) * np.sum((y_train_hat - y_train)**2)\n",
    "\n",
    "    # Evaluating the model on the test set\n",
    "    y_test_hat = X_test.dot(theta)\n",
    "    mse_test = (1/m_test) * np.sum((y_test_hat - y_test)**2)\n",
    "\n",
    "    # Storing the results\n",
    "    train_mse.append(mse_train)\n",
    "    test_mse.append(mse_test)\n",
    "\n",
    "avg_train_mse = np.mean(train_mse)\n",
    "avg_test_mse = np.mean(test_mse)\n",
    "\n",
    "print(\"Average Training MSE:\", avg_train_mse)\n",
    "print(\"Average Test MSE:\", avg_test_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec21a1-49d9-47da-86d2-56ccd3819225",
   "metadata": {},
   "source": [
    "# Implementing a Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97b0321-36b7-451b-94b1-1e61dcaabe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best λ value is:  100.0\n",
      "The corresponding test error is:  29.61522009733349\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "lambda_vals = np.logspace(1,7,num=13)\n",
    "best_lambda = None\n",
    "lowest_test_j = float('inf')\n",
    "\n",
    "for lam_val in lambda_vals:\n",
    "    j_train = []\n",
    "    j_test = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Splitting the dataset into train set and test set\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        m_train, m_test = X_train.shape[0], X_test.shape[0]\n",
    "    \n",
    "        # Appending a column of ones to X_train and X_test to account for the bias term \n",
    "        X_train = np.append(X_train, np.ones((m_train,1)), axis = 1)\n",
    "        X_test = np.append(X_test, np.ones((m_test, 1)), axis=1)\n",
    "    \n",
    "        # Reshaping y_train and y_test\n",
    "        y_train = y_train.reshape(m_train,1)\n",
    "        y_test = y_test.reshape(m_test,1)\n",
    "\n",
    "        # Creating identity matrix for regularization\n",
    "        I = np.eye(X_train.shape[1])\n",
    "        I[-1, -1] = 0 # This is done as the bias term should not be regulaized\n",
    "    \n",
    "        # Computing Theta using the Normal Equation (Closed-Form Solution)\n",
    "        theta = np.dot(np.linalg.inv((np.dot(X_train.T, X_train)) + lam_val*I), np.dot(X_train.T, y_train))\n",
    "    \n",
    "        # Evaluating the model on the train set\n",
    "        y_train_hat = X_train.dot(theta)\n",
    "        mse_train = (1/m_train) * np.sum((y_train_hat - y_train)**2)\n",
    "        j_train.append(mse_train + lam_val*0.5*np.sum(theta**2))\n",
    "    \n",
    "        # Evaluating the model on the test set\n",
    "        y_test_hat = X_test.dot(theta)\n",
    "        mse_test = (1/m_test) * np.sum((y_test_hat - y_test)**2)\n",
    "        j_test .append(mse_test)\n",
    "\n",
    "    avg_j_train = np.mean(j_train)\n",
    "    avg_j_test = np.mean(j_test)\n",
    "\n",
    "    if avg_j_test < lowest_test_j:\n",
    "        lowest_test_j = avg_j_test\n",
    "        best_lambda = lam_val\n",
    "\n",
    "print(\"The best λ value is: \", best_lambda)\n",
    "print(\"The corresponding test error is: \", lowest_test_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990e84b-ac72-48ef-a3d6-0ab4cf88be8f",
   "metadata": {},
   "source": [
    "# Estimaing the Performace of Model with Optimal λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd17a54-918b-4726-83bf-6e01a8fa0fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Score: 23.609927954689702\n",
      "Average Test Score: 29.61522009733349\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Splitting the dataset into train set and test set\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    m_train, m_test = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "    # Appending a column of ones to X_train and X_test to account for the bias term \n",
    "    X_train = np.append(X_train, np.ones((m_train,1)), axis = 1)\n",
    "    X_test = np.append(X_test, np.ones((m_test, 1)), axis=1)\n",
    "\n",
    "    # Reshaping y_train and y_test\n",
    "    y_train = y_train.reshape(m_train,1)\n",
    "    y_test = y_test.reshape(m_test,1)\n",
    "\n",
    "    # Creating identity matrix for regularization\n",
    "    I = np.eye(X_train.shape[1])\n",
    "    I[-1, -1] = 0 # This is done as the bias term should not be regulaized\n",
    "\n",
    "    # Computing Theta using the Normal Equation (Closed-Form Solution)\n",
    "    theta = np.dot(np.linalg.inv((np.dot(X_train.T, X_train)) + best_lambda*I), np.dot(X_train.T, y_train))\n",
    "\n",
    "    # Evaluating the model on the train set\n",
    "    y_train_hat = X_train.dot(theta)\n",
    "    mse_train = (1/m_train) * np.sum((y_train_hat - y_train)**2)\n",
    "    train_mse.append(mse_train)\n",
    "    \n",
    "    # Evaluating the model on the test set\n",
    "    y_test_hat = X_test.dot(theta)\n",
    "    mse_test = (1/m_test) * np.sum((y_test_hat - y_test)**2)\n",
    "    test_mse.append(mse_test)\n",
    "\n",
    "avg_train_mse = np.mean(train_mse)\n",
    "avg_test_mse = np.mean(test_mse)\n",
    "\n",
    "print(\"Average Training Score:\", avg_train_mse)\n",
    "print(\"Average Test Score:\", avg_test_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4952c78-a79f-4a3e-a14f-a839665b9728",
   "metadata": {},
   "source": [
    "# Implementing a Polynomial Transformation of Degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31450d90-c533-4f06-b3a0-ec082cdc0d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Score: 7.481646104598366\n",
      "Average Test Score: 65.55557808784023\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Splitting the dataset into train set and test set\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    m_train, m_test = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "    # Polynomial Transformation\n",
    "    poly = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    # Appending a column of ones to X_train and X_test to account for the bias term \n",
    "    X_train_poly = np.append(X_train_poly, np.ones((m_train,1)), axis = 1)\n",
    "    X_test_poly = np.append(X_test_poly, np.ones((m_test, 1)), axis=1)\n",
    "\n",
    "    # Reshaping y_train and y_test\n",
    "    y_train = y_train.reshape(m_train,1)\n",
    "    y_test = y_test.reshape(m_test,1)\n",
    "\n",
    "    # Creating identity matrix for regularization\n",
    "    I = np.eye(X_train_poly.shape[1])\n",
    "    I[-1, -1] = 0 # This is done as the bias term should not be regulaized\n",
    "\n",
    "    # Computing Theta using the Normal Equation (Closed-Form Solution)\n",
    "    theta = np.dot(np.linalg.inv((np.dot(X_train_poly.T, X_train_poly))+ best_lambda*I), np.dot(X_train_poly.T, y_train))\n",
    "\n",
    "    # Evaluating the model on the train set\n",
    "    y_train_hat = X_train_poly.dot(theta)\n",
    "    mse_train = (1/m_train) * np.sum((y_train_hat - y_train)**2)\n",
    "    train_mse.append(mse_train)\n",
    "    \n",
    "    # Evaluating the model on the test set\n",
    "    y_test_hat = X_test_poly.dot(theta)\n",
    "    mse_test = (1/m_test) * np.sum((y_test_hat - y_test)**2)\n",
    "    test_mse.append(mse_test)\n",
    "\n",
    "avg_train_mse = np.mean(train_mse)\n",
    "avg_test_mse = np.mean(test_mse)\n",
    "\n",
    "print(\"Average Training Score:\", avg_train_mse)\n",
    "print(\"Average Test Score:\", avg_test_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b3ce86-aabe-4dc2-b52b-004fe333cc67",
   "metadata": {},
   "source": [
    "# Implementing Multivariate Linear Regression using the Gradient Descent method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2217635-3646-4063-b581-b91eda68377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training MSE: 21.3993924174482\n",
      "Average Test MSE: 34.705267719600265\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Splitting the dataset into train set and test set\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    m_train, m_test = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "    # Appending a column of ones to X_train and X_test to account for the bias term\n",
    "    X_train = np.append(X_train, np.ones((m_train, 1)), axis=1)\n",
    "    X_test = np.append(X_test, np.ones((m_test, 1)), axis=1)\n",
    "\n",
    "    # Reshaping y_train and y_test\n",
    "    y_train = y_train.reshape(m_train, 1)\n",
    "    y_test = y_test.reshape(m_test, 1)\n",
    "\n",
    "    # Hyperparameters\n",
    "    eta = 0.01  \n",
    "    n_iterations = 10_000\n",
    "    tolerance = 1e-8\n",
    "\n",
    "    # Random Initialization\n",
    "    theta = np.random.randn(X_train.shape[1], 1)\n",
    "\n",
    "    # Gradient Descent\n",
    "    for i in range(n_iterations):\n",
    "        gradients = (2/m_train) * (X_train.T).dot(X_train.dot(theta) - y_train)\n",
    "        theta = theta - eta * gradients\n",
    "\n",
    "        if np.linalg.norm(gradients) < tolerance:\n",
    "            break\n",
    "\n",
    "    # Evaluating the model on the train set\n",
    "    y_train_hat = X_train.dot(theta)\n",
    "    mse_train = (1/m_train) * np.sum((y_train_hat - y_train)**2)\n",
    "    train_mse.append(mse_train)\n",
    "    \n",
    "    # Evaluating the model on the test set\n",
    "    y_test_hat = X_test.dot(theta)\n",
    "    mse_test = (1/m_test) * np.sum((y_test_hat - y_test)**2)\n",
    "    test_mse.append(mse_test)\n",
    "\n",
    "# Calculating average MSE\n",
    "avg_train_mse = np.mean(train_mse)\n",
    "avg_test_mse = np.mean(test_mse)\n",
    "\n",
    "print(\"Average Training MSE:\", avg_train_mse)\n",
    "print(\"Average Test MSE:\", avg_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31754db0-3273-4984-bf29-3df676a1499b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a150791-5a67-4810-b6da-5c9149594106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c3aba-f661-4525-bb20-6ab71b324804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352fe6b-cd18-4c8d-8447-b331db2dab1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
